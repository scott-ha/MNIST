{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)\n",
    "\n",
    "def viz_img(y_pred):\n",
    "    n = 10\n",
    "    fig = plt.figure(1)\n",
    "    box_index = 1\n",
    "    for cluster in range(10):\n",
    "        result = np.where(y_pred == cluster)\n",
    "        for i in np.random.choice(result[0].tolist(), n, replace=False):\n",
    "            ax = fig.add_subplot(n, n, box_index)\n",
    "            plt.imshow(x_train[i].reshape(28, 28))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            box_index += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# configure\n",
    "encoding_dim = 200\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "\n",
    "# layers\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "\n",
    "# Models\n",
    "autoencoder = Model(input_img, decoded) # autoencoder\n",
    "\n",
    "encoder = Model(input_img, encoded) # encoder\n",
    "\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input)) # decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3913 - rmse: 0.3180 - recall: 0.2631 - val_loss: 0.2742 - val_rmse: 0.2595 - val_recall: 0.2357\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2668 - rmse: 0.2549 - recall: 0.2443 - val_loss: 0.2573 - val_rmse: 0.2493 - val_recall: 0.2975\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2502 - rmse: 0.2432 - recall: 0.3334 - val_loss: 0.2399 - val_rmse: 0.2358 - val_recall: 0.3960\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2330 - rmse: 0.2296 - recall: 0.4446 - val_loss: 0.2234 - val_rmse: 0.2224 - val_recall: 0.4954\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.2181 - rmse: 0.2176 - recall: 0.5294 - val_loss: 0.2100 - val_rmse: 0.2116 - val_recall: 0.5617\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.2063 - rmse: 0.2081 - recall: 0.5851 - val_loss: 0.1995 - val_rmse: 0.2031 - val_recall: 0.6124\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1969 - rmse: 0.2005 - recall: 0.6238 - val_loss: 0.1911 - val_rmse: 0.1961 - val_recall: 0.6425\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1891 - rmse: 0.1940 - recall: 0.6519 - val_loss: 0.1840 - val_rmse: 0.1901 - val_recall: 0.6687\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1825 - rmse: 0.1885 - recall: 0.6744 - val_loss: 0.1780 - val_rmse: 0.1848 - val_recall: 0.6920\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.1768 - rmse: 0.1835 - recall: 0.6932 - val_loss: 0.1726 - val_rmse: 0.1801 - val_recall: 0.7068\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1718 - rmse: 0.1790 - recall: 0.7091 - val_loss: 0.1679 - val_rmse: 0.1759 - val_recall: 0.7102\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1672 - rmse: 0.1749 - recall: 0.7223 - val_loss: 0.1636 - val_rmse: 0.1719 - val_recall: 0.7277\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1631 - rmse: 0.1711 - recall: 0.7346 - val_loss: 0.1596 - val_rmse: 0.1682 - val_recall: 0.7383\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1593 - rmse: 0.1675 - recall: 0.7447 - val_loss: 0.1560 - val_rmse: 0.1647 - val_recall: 0.7536\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1558 - rmse: 0.1642 - recall: 0.7547 - val_loss: 0.1526 - val_rmse: 0.1614 - val_recall: 0.7607\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1526 - rmse: 0.1611 - recall: 0.7632 - val_loss: 0.1495 - val_rmse: 0.1584 - val_recall: 0.7689\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1496 - rmse: 0.1581 - recall: 0.7712 - val_loss: 0.1466 - val_rmse: 0.1555 - val_recall: 0.7776\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1468 - rmse: 0.1553 - recall: 0.7786 - val_loss: 0.1441 - val_rmse: 0.1530 - val_recall: 0.7733\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1442 - rmse: 0.1527 - recall: 0.7845 - val_loss: 0.1414 - val_rmse: 0.1503 - val_recall: 0.7848\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1417 - rmse: 0.1502 - recall: 0.7909 - val_loss: 0.1391 - val_rmse: 0.1478 - val_recall: 0.7903\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1394 - rmse: 0.1478 - recall: 0.7964 - val_loss: 0.1368 - val_rmse: 0.1455 - val_recall: 0.7986\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1372 - rmse: 0.1456 - recall: 0.8016 - val_loss: 0.1347 - val_rmse: 0.1433 - val_recall: 0.8030\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1352 - rmse: 0.1434 - recall: 0.8065 - val_loss: 0.1326 - val_rmse: 0.1411 - val_recall: 0.8082\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1332 - rmse: 0.1413 - recall: 0.8107 - val_loss: 0.1307 - val_rmse: 0.1390 - val_recall: 0.8193\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1313 - rmse: 0.1393 - recall: 0.8154 - val_loss: 0.1290 - val_rmse: 0.1371 - val_recall: 0.8141\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1295 - rmse: 0.1374 - recall: 0.8190 - val_loss: 0.1272 - val_rmse: 0.1352 - val_recall: 0.8210\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1278 - rmse: 0.1355 - recall: 0.8228 - val_loss: 0.1255 - val_rmse: 0.1333 - val_recall: 0.8236\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1262 - rmse: 0.1337 - recall: 0.8262 - val_loss: 0.1239 - val_rmse: 0.1315 - val_recall: 0.8288\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1246 - rmse: 0.1319 - recall: 0.8298 - val_loss: 0.1223 - val_rmse: 0.1297 - val_recall: 0.8329\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1231 - rmse: 0.1302 - recall: 0.8332 - val_loss: 0.1209 - val_rmse: 0.1282 - val_recall: 0.8310\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1216 - rmse: 0.1286 - recall: 0.8360 - val_loss: 0.1194 - val_rmse: 0.1265 - val_recall: 0.8360\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1202 - rmse: 0.1269 - recall: 0.8390 - val_loss: 0.1180 - val_rmse: 0.1249 - val_recall: 0.8376\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1188 - rmse: 0.1253 - recall: 0.8417 - val_loss: 0.1167 - val_rmse: 0.1232 - val_recall: 0.8436\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1175 - rmse: 0.1238 - recall: 0.8444 - val_loss: 0.1154 - val_rmse: 0.1217 - val_recall: 0.8452\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1162 - rmse: 0.1223 - recall: 0.8471 - val_loss: 0.1142 - val_rmse: 0.1203 - val_recall: 0.8444\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1150 - rmse: 0.1208 - recall: 0.8492 - val_loss: 0.1128 - val_rmse: 0.1186 - val_recall: 0.8572\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1138 - rmse: 0.1193 - recall: 0.8521 - val_loss: 0.1117 - val_rmse: 0.1173 - val_recall: 0.8513\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1126 - rmse: 0.1179 - recall: 0.8539 - val_loss: 0.1105 - val_rmse: 0.1157 - val_recall: 0.8586\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1115 - rmse: 0.1165 - recall: 0.8563 - val_loss: 0.1095 - val_rmse: 0.1145 - val_recall: 0.8569\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1104 - rmse: 0.1152 - recall: 0.8582 - val_loss: 0.1084 - val_rmse: 0.1131 - val_recall: 0.8590\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1093 - rmse: 0.1139 - recall: 0.8604 - val_loss: 0.1074 - val_rmse: 0.1119 - val_recall: 0.8586\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1083 - rmse: 0.1126 - recall: 0.8620 - val_loss: 0.1063 - val_rmse: 0.1104 - val_recall: 0.8683\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1074 - rmse: 0.1113 - recall: 0.8642 - val_loss: 0.1054 - val_rmse: 0.1094 - val_recall: 0.8637\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1064 - rmse: 0.1101 - recall: 0.8657 - val_loss: 0.1045 - val_rmse: 0.1082 - val_recall: 0.8671\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1055 - rmse: 0.1090 - recall: 0.8674 - val_loss: 0.1036 - val_rmse: 0.1070 - val_recall: 0.8684\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1046 - rmse: 0.1078 - recall: 0.8689 - val_loss: 0.1028 - val_rmse: 0.1059 - val_recall: 0.8692\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1038 - rmse: 0.1068 - recall: 0.8703 - val_loss: 0.1020 - val_rmse: 0.1049 - val_recall: 0.8708\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1030 - rmse: 0.1057 - recall: 0.8717 - val_loss: 0.1011 - val_rmse: 0.1037 - val_recall: 0.8774\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1022 - rmse: 0.1047 - recall: 0.8733 - val_loss: 0.1004 - val_rmse: 0.1028 - val_recall: 0.8731\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1015 - rmse: 0.1037 - recall: 0.8745 - val_loss: 0.0997 - val_rmse: 0.1018 - val_recall: 0.8746\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1007 - rmse: 0.1027 - recall: 0.8756 - val_loss: 0.0990 - val_rmse: 0.1008 - val_recall: 0.8767\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1000 - rmse: 0.1018 - recall: 0.8769 - val_loss: 0.0983 - val_rmse: 0.0998 - val_recall: 0.8814\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0994 - rmse: 0.1009 - recall: 0.8782 - val_loss: 0.0977 - val_rmse: 0.0990 - val_recall: 0.8783\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0987 - rmse: 0.1000 - recall: 0.8793 - val_loss: 0.0971 - val_rmse: 0.0983 - val_recall: 0.8764\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0981 - rmse: 0.0992 - recall: 0.8801 - val_loss: 0.0965 - val_rmse: 0.0974 - val_recall: 0.8812\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0975 - rmse: 0.0983 - recall: 0.8812 - val_loss: 0.0959 - val_rmse: 0.0965 - val_recall: 0.8832\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0970 - rmse: 0.0976 - recall: 0.8822 - val_loss: 0.0953 - val_rmse: 0.0957 - val_recall: 0.8842\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0964 - rmse: 0.0968 - recall: 0.8831 - val_loss: 0.0948 - val_rmse: 0.0951 - val_recall: 0.8826\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0959 - rmse: 0.0960 - recall: 0.8840 - val_loss: 0.0943 - val_rmse: 0.0944 - val_recall: 0.8841\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0954 - rmse: 0.0953 - recall: 0.8849 - val_loss: 0.0938 - val_rmse: 0.0936 - val_recall: 0.8864\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0949 - rmse: 0.0946 - recall: 0.8858 - val_loss: 0.0933 - val_rmse: 0.0928 - val_recall: 0.8894\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0944 - rmse: 0.0940 - recall: 0.8868 - val_loss: 0.0929 - val_rmse: 0.0924 - val_recall: 0.8851\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0939 - rmse: 0.0933 - recall: 0.8874 - val_loss: 0.0924 - val_rmse: 0.0915 - val_recall: 0.8908\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0935 - rmse: 0.0927 - recall: 0.8883 - val_loss: 0.0920 - val_rmse: 0.0909 - val_recall: 0.8918\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0931 - rmse: 0.0921 - recall: 0.8891 - val_loss: 0.0916 - val_rmse: 0.0904 - val_recall: 0.8907\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0926 - rmse: 0.0915 - recall: 0.8897 - val_loss: 0.0912 - val_rmse: 0.0898 - val_recall: 0.8919\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0922 - rmse: 0.0909 - recall: 0.8905 - val_loss: 0.0908 - val_rmse: 0.0893 - val_recall: 0.8906\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0919 - rmse: 0.0903 - recall: 0.8911 - val_loss: 0.0904 - val_rmse: 0.0886 - val_recall: 0.8948\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0915 - rmse: 0.0898 - recall: 0.8920 - val_loss: 0.0900 - val_rmse: 0.0881 - val_recall: 0.8942\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.0911 - rmse: 0.0892 - recall: 0.8925 - val_loss: 0.0897 - val_rmse: 0.0876 - val_recall: 0.8952\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0908 - rmse: 0.0887 - recall: 0.8932 - val_loss: 0.0893 - val_rmse: 0.0871 - val_recall: 0.8949\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0904 - rmse: 0.0882 - recall: 0.8938 - val_loss: 0.0890 - val_rmse: 0.0866 - val_recall: 0.8968\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0901 - rmse: 0.0877 - recall: 0.8943 - val_loss: 0.0887 - val_rmse: 0.0860 - val_recall: 0.8988\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0898 - rmse: 0.0873 - recall: 0.8952 - val_loss: 0.0884 - val_rmse: 0.0857 - val_recall: 0.8961\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0895 - rmse: 0.0868 - recall: 0.8956 - val_loss: 0.0881 - val_rmse: 0.0852 - val_recall: 0.8965\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0891 - rmse: 0.0863 - recall: 0.8963 - val_loss: 0.0878 - val_rmse: 0.0847 - val_recall: 0.8977\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0889 - rmse: 0.0859 - recall: 0.8969 - val_loss: 0.0875 - val_rmse: 0.0843 - val_recall: 0.8990\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0886 - rmse: 0.0855 - recall: 0.8974 - val_loss: 0.0872 - val_rmse: 0.0839 - val_recall: 0.8987\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0883 - rmse: 0.0850 - recall: 0.8979 - val_loss: 0.0870 - val_rmse: 0.0834 - val_recall: 0.9008\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0880 - rmse: 0.0846 - recall: 0.8986 - val_loss: 0.0867 - val_rmse: 0.0830 - val_recall: 0.9001\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0878 - rmse: 0.0842 - recall: 0.8991 - val_loss: 0.0864 - val_rmse: 0.0826 - val_recall: 0.9023\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0875 - rmse: 0.0838 - recall: 0.8996 - val_loss: 0.0862 - val_rmse: 0.0823 - val_recall: 0.9011\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0872 - rmse: 0.0834 - recall: 0.9001 - val_loss: 0.0860 - val_rmse: 0.0819 - val_recall: 0.9015\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0870 - rmse: 0.0830 - recall: 0.9007 - val_loss: 0.0857 - val_rmse: 0.0815 - val_recall: 0.9028\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0868 - rmse: 0.0827 - recall: 0.9011 - val_loss: 0.0855 - val_rmse: 0.0811 - val_recall: 0.9049\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0865 - rmse: 0.0823 - recall: 0.9016 - val_loss: 0.0853 - val_rmse: 0.0807 - val_recall: 0.9046\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0863 - rmse: 0.0820 - recall: 0.9022 - val_loss: 0.0850 - val_rmse: 0.0804 - val_recall: 0.9054\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0861 - rmse: 0.0816 - recall: 0.9026 - val_loss: 0.0848 - val_rmse: 0.0801 - val_recall: 0.9047\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0859 - rmse: 0.0813 - recall: 0.9030 - val_loss: 0.0846 - val_rmse: 0.0797 - val_recall: 0.9042\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0857 - rmse: 0.0809 - recall: 0.9034 - val_loss: 0.0844 - val_rmse: 0.0794 - val_recall: 0.9072\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0854 - rmse: 0.0806 - recall: 0.9040 - val_loss: 0.0842 - val_rmse: 0.0791 - val_recall: 0.9051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0852 - rmse: 0.0803 - recall: 0.9044 - val_loss: 0.0840 - val_rmse: 0.0788 - val_recall: 0.9071\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0850 - rmse: 0.0800 - recall: 0.9048 - val_loss: 0.0839 - val_rmse: 0.0785 - val_recall: 0.9067\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0849 - rmse: 0.0796 - recall: 0.9052 - val_loss: 0.0837 - val_rmse: 0.0781 - val_recall: 0.9078\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0847 - rmse: 0.0793 - recall: 0.9057 - val_loss: 0.0835 - val_rmse: 0.0779 - val_recall: 0.9062\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0845 - rmse: 0.0790 - recall: 0.9061 - val_loss: 0.0833 - val_rmse: 0.0776 - val_recall: 0.9081\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0843 - rmse: 0.0787 - recall: 0.9065 - val_loss: 0.0831 - val_rmse: 0.0773 - val_recall: 0.9087\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0841 - rmse: 0.0785 - recall: 0.9069 - val_loss: 0.0830 - val_rmse: 0.0770 - val_recall: 0.9086\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0839 - rmse: 0.0782 - recall: 0.9074 - val_loss: 0.0828 - val_rmse: 0.0768 - val_recall: 0.9080\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0838 - rmse: 0.0779 - recall: 0.9077 - val_loss: 0.0826 - val_rmse: 0.0764 - val_recall: 0.9105\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1))\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn)\n",
    "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "# train autoencoder\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[rmse, recall])\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=512,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "\n",
    "# encoding result\n",
    "encoded_imgs = encoder.predict(x_train)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spherecluster import SphericalKMeans\n",
    "# from sklearn.cluster import _k_means\n",
    "\n",
    "# skm = SphericalKMeans(n_clusters=10)\n",
    "# skm.fit(x_train)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skm = KMeans(init=\"k-means++\", n_clusters=10, random_state=0)\n",
    "skm.fit(x_train)\n",
    "# y_pred = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ca1dfed542ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mviz_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'skm' is not defined"
     ]
    }
   ],
   "source": [
    "viz_img(skm.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
